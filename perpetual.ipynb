{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db7071ac",
   "metadata": {},
   "source": [
    "## This notebook investigates the popular 'perpetual swap' arbitrage on crytpo markets.\n",
    "\n",
    "1a) First we take a look at perpetual swaps and 'cash and carry' arbitrage opportunities. <br>\n",
    "1b) We derive the mathematical foundations. <br>\n",
    "2) Then we take a look on empiricial opportunities. <br>\n",
    "3) Finally we take a look at CPI arbitrage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81679e00",
   "metadata": {},
   "source": [
    "### Data:\n",
    "- We gather data from binance.com, the largest perpetual swaps marketplace.\n",
    "- The data for the two most liquid markets (BTC/USDT and ETH/USDT) consists of 8h intervals from 11/2019-03/2022.\n",
    "- We gather both spot data as well as derivative data from the same exchange, thus arbitrageurs have minimal barriers to access opportunities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87780d66",
   "metadata": {},
   "source": [
    "### 1a) About perpetual swaps and 'cash and carry' arbitrage\n",
    "\n",
    "Perpetual swaps are very short-term futures.\n",
    "- Perpetual swaps are very short-term futures, whereas a 'funding rate' is used to keep the price between the derivative and index in balance.\n",
    "- The funding rate is higher (lower) the higher (lower) the derivative trades above (below) the underlying index.\n",
    "- Every 8h the long position pays the short position - vice versa if the funding rate is negative.\n",
    "- The perpetual swaps is the most popular financial instruments in crypto markets. Perpetual swaps account for USD 75-125 billion daily traded volume, whereas 40-60% is traded on Binance.com.\n",
    "\n",
    "Crypto markets have some interesting unique properties.\n",
    "- Due to the absence of prime broker and scattered trading venues, margins might be posted seperately for both sides of the trade. This makes trading capital intensive.\n",
    "- Trading in crypto markets occurs 24/7. Regular cash-settled future instruments (e.g. as offered by the Chicago CME) has low demand, due to the troubles of managing margin during non-banking hours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe29595",
   "metadata": {},
   "source": [
    "Cash and carry trade for perpetual swaps\n",
    "- Using the cost of carry model from Fama and French (1988), we can write the the price of a future contract in t ($F_t$) as function of the spot price ($S_t$), the risk free rate ($r_t$), the costs of storage ($w_t$) and the cost of convenience ($y_t$):\n",
    "$F_t^T = S_t * T * (r_t^T+w_t^T-y_t^T)$\n",
    "\n",
    "- On crypto markets the funding rate $fr_t$ would be the combined compensation for the costs of capital, storage and convenience.\n",
    "- As we will see the funding rate already includes a fair parameter for the risk free rate.\n",
    "- The cost of storage could be interpreted as the default-risk premia to store collateral on a crypto exchange. However, leading crypto exchanges insure collateral with an in-house insurance fund, akin to deposit insurance in traditional banking.\n",
    "- Thus, one could argue that the funding rate is mostly driven by the cost of convenience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a910c04f",
   "metadata": {},
   "source": [
    "It is possible to exploit the cost of convenience.\n",
    "- The funding rate consists of a premium component and a fixed interest rate component $fundingrate_t = premium_t + interest$.\n",
    "- The interest rate $i$ component is fixed to compensate for difference of capital costs between the base and the quoted asset.\n",
    "- The premium is the deviation between the spot and the derivative price $(F_t/S_t)-1$.\n",
    "- The funding rate can be defined as $fundingrate_t = fr_t = (F_t/S_t)-1 + i$\n",
    "- If the funding rate is positive (i.e. the price of the deriviative is larger than the price of the index), long positions have to pay short positions. This incentivizes more short positions and promotes the equilbrium between derivative and spot.\n",
    "- If the funding rate is negative (i.e. the price of the deriviative is below the price of the index), short positions have to pay long positions. This incentivizes more long positions and promotes equilbrium between derivative and spot.\n",
    "- There exists a strategy to capture the funding rate payments by going either long or short the perpetual swap.\n",
    "- The price risk can be hedged by taking the opposite direction on the spot market.\n",
    "- Holding both till expiry will yield the funding rate over time.\n",
    "- Note: we do not consider fees and margin requirements.\n",
    "\n",
    "![](perp_swap.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aff50d",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccff097c",
   "metadata": {},
   "source": [
    "### 1b) Mathematical foundations\n",
    "We explore the limits and calculation of the perpetual swap arbitrage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6048a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e068d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the index price to 100, and fluctuating the perpetual price. The interest rate is market typical and set to 0.01% each 8h.\n",
    "# This is equivalent to 9.5% per annum.\n",
    "index = 100\n",
    "interest = 0.0001\n",
    "perp = np.arange(98, 102, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce4b6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing arbitrage when the funding rate is positive\n",
    "def positive(perp, index, interest, fee):\n",
    "    premium = (perp/index)-1\n",
    "    fr_8h = (premium + interest)\n",
    "    rtrn = fr_8h/2 - fee\n",
    "    return rtrn*3*365\n",
    "\n",
    "#implementing arbitrage when the funding rate is negative\n",
    "def negative(perp, index, interest, fee):\n",
    "    premium = (perp/index)-1\n",
    "    fr_8h = premium + interest\n",
    "    rtrn = -1*(fr_8h)/2 - fee\n",
    "    return rtrn*3*365\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(15, 6), sharey=True)\n",
    "\n",
    "fee = 0.0000\n",
    "axs[0].plot(perp/index-1, positive(perp, index, interest, fee), 'b-')\n",
    "axs[0].plot(perp/index-1, negative(perp, index, interest, fee), 'g-')\n",
    "\n",
    "fee = 0.0005\n",
    "axs[1].plot(perp/index-1, positive(perp, index, interest, fee), 'b--')\n",
    "axs[1].plot(perp/index-1, negative(perp, index, interest, fee), 'g--')\n",
    "axs[1].plot([-.0009,.0007], [0,0], 'r-')\n",
    "axs[1].plot([.0007,.015], [0,7.5], 'r-')\n",
    "axs[1].plot([-.015,-.0009], [7.5,0], 'r-')\n",
    "\n",
    "for i in range(0,2):\n",
    "    axs[i].set_ylim(-2.5,2.5)\n",
    "    axs[i].set_xlim(-0.01,0.01)\n",
    "\n",
    "    vals = axs[i].get_xticks()\n",
    "    axs[i].set_xticklabels(['{:,.1%}'.format(x) for x in vals])\n",
    "\n",
    "    vals = axs[i].get_yticks()\n",
    "    axs[i].set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "\n",
    "    axs[i].set_xlabel('Deviation: Perp/Index')\n",
    "    axs[0].set_ylabel('Return of Strategy')\n",
    "    axs[0].legend(['Positive $fr_t$: short', 'Negative $fr_t$: long'], loc='upper right')\n",
    "    axs[1].legend(['Positive $fr_t$ (incl fees)', 'Negative $fr_t$ (incl fees)', 'Perfect strategy (incl fees)'], loc='upper right')\n",
    "    \n",
    "txt = 'The figure displays returns from arbitraging the funding rate. If the funding rate is positive (negative) one shorts (longs) the derivative and longs (shorts) the spot. \\n The return is large, when the deviation between the derivative and spot widens. However, the return is heavily dependent on fees and margin management. The right chart introduces (5bps) fees. \\n The red line depicts a perfect arbitrageur, i.e. perfect timing the funding rates and refraining from trades, if the returns are smaller then the costs.'\n",
    "fig.text(.5, -.1, txt, ha='center', fontstyle='italic')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5726ac69",
   "metadata": {},
   "source": [
    "### 2) Empirical arbitrage opportunities\n",
    "The funding rate has been significant in the past. We calculate the returns on the above mentioned strategy on the historical data. We calculate the return in two fashions: with and without compounding effects (reinvesting the profits into the strategy).\n",
    "We assume no fees, liquidation risk and efficient markets (shorting is possible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e27393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load relevant data\n",
    "funding_rate = pd.read_csv('rate_eth_usdt.csv', parse_dates=['timestamp'])\n",
    "funding_rate = funding_rate.rename(columns={'rate': 'funding_rate'})\n",
    "perp = pd.read_csv('perp_eth_usdt_1h.csv', parse_dates=['timestamp'])\n",
    "spot = pd.read_csv('spot_eth_usdt_1h.csv', parse_dates=['timestamp'])\n",
    "\n",
    "#rate_sample = rate[(rate['timestamp'] >= '2021-03-01') & (rate['timestamp'] <= '2022-03-01')].reset_index(drop=True)\n",
    "#perp_sample = perp[(perp['timestamp'] >= '2021-03-01') & (perp['timestamp'] <= '2022-03-01')].reset_index(drop=True)\n",
    "#spot_sample = spot[(spot['timestamp'] >= '2021-03-01') & (spot['timestamp'] <= '2022-03-01')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c961ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look at the funding rate over time\n",
    "df = funding_rate[['epoch', 'timestamp', 'funding_rate']]\n",
    "df = pd.merge(df,\n",
    "                 spot[['epoch', 'close']],\n",
    "                 on='epoch', \n",
    "                 how='left')\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10,4))\n",
    "\n",
    "ax.plot(df['timestamp'], df['funding_rate'])\n",
    "secax = ax.twinx()\n",
    "secax.plot(df['timestamp'], df['close'], color = 'orange')\n",
    "secax.set_yscale('log')\n",
    "secax.set_yticks([])\n",
    "\n",
    "vals = ax.get_yticks()\n",
    "ax.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
    "\n",
    "ax.set_ylabel('8h funding rate')\n",
    "\n",
    "txt = 'The figure displays the 8h funding rate of the ETH/USDT perpetual swap on Binance from 11/2019 to 03/2022. The orange line denotes the log of the price over time. \\n The funding rate tends to decline over time.'\n",
    "fig.text(.5, -.1, txt, ha='center', fontstyle='italic')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde03f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now calculate common statistics, such as standard deviation, return, maximum drawdown.\n",
    "#create a dataframe for the calculations\n",
    "df = funding_rate.copy()\n",
    "df['pf'] = 0.0\n",
    "\n",
    "#calculate the return capturing the funding rate over time. Note: This calculation includes compounding effects.\n",
    "df['pf'][0] = 1 * (1+df['funding_rate'][0])\n",
    "for i in range(1,len(df)):\n",
    "    df['pf'][i] = df['pf'][i-1]*(1+df['funding_rate'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad83fe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate and plot maxmimum drawdown\n",
    "window = 3*365 #one year\n",
    "\n",
    "roll_max = df['pf'].rolling(window, min_periods=1).max()\n",
    "\n",
    "daily_drawdown = df['pf']/roll_max - 1.0\n",
    "max_daily_drawdown = daily_drawdown.rolling(window, min_periods=1).min()\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10,4))\n",
    "\n",
    "ax.plot(df['timestamp'], daily_drawdown)\n",
    "ax.plot(df['timestamp'], max_daily_drawdown)\n",
    "\n",
    "vals = ax.get_yticks()\n",
    "ax.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
    "\n",
    "ax.legend(['daily drawdown', 'maximum drawdown'])\n",
    "ax.set_ylabel('8h funding rate')\n",
    "\n",
    "txt = f'The figure displays the possible drawdowns for perpetual swap arbitrage on Binance from 11/2019 to 03/2022. \\n The maximum drawdown at {np.round(daily_drawdown.min()*100,2)}% is suprisingly small.'\n",
    "fig.text(.5, -.1, txt, ha='center', fontstyle='italic')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07eb968",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard deviation\n",
    "std = df['funding_rate'].std()\n",
    "std_annualized = std * np.sqrt(3*365)\n",
    "\n",
    "#calculating the return without compounding effect.\n",
    "mreturn = df['funding_rate'].mean()\n",
    "mreturn_annualized = mreturn*3*365\n",
    "\n",
    "#calculating sharpe ratio, yet without substracting a risk free component\n",
    "sharpe = (mreturn_annualized/std_annualized)\n",
    "\n",
    "\n",
    "print('Capturing the funding rate since the start would have compounded in a gain of:', np.round((df['pf'].iloc[-1]-1)*100,2), '%')\n",
    "print(np.round(mreturn_annualized*100, 2), '% mean return (annualized)')\n",
    "print(np.round(std_annualized*100, 2), '% standard deviation (annualized)')\n",
    "print(np.round(sharpe,2), 'sharpe ratio (annualized)')\n",
    "print(np.round(daily_drawdown.min()*100,2), '% maximum drawdown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550f1366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the statistics into years\n",
    "df_2019 = df[(df['timestamp'] < pd.to_datetime('2020-01-01'))].reset_index(drop=True)\n",
    "df_2020 = df[(df['timestamp'] >= pd.to_datetime('2020-01-01')) & (df['timestamp'] < pd.to_datetime('2021-01-01'))].reset_index(drop=True)\n",
    "df_2021 = df[(df['timestamp'] >= pd.to_datetime('2021-01-01')) & (df['timestamp'] < pd.to_datetime('2022-01-01'))].reset_index(drop=True)\n",
    "df_2022 = df[(df['timestamp'] >= pd.to_datetime('2022-01-01'))].reset_index(drop=True) \n",
    "\n",
    "results = pd.DataFrame(\n",
    "    {'mean return': [np.round(df_2019['funding_rate'].mean()*3*365,4), np.round(df_2020['funding_rate'].mean()*3*365,4), np.round(df_2021['funding_rate'].mean()*3*365,4), np.round(df_2022['funding_rate'].mean()*3*365,4)],\n",
    "    'standard deviation': [np.round(df_2019['funding_rate'].std()*np.sqrt(3*365),4), np.round(df_2020['funding_rate'].std()*np.sqrt(3*365),4), np.round(df_2021['funding_rate'].std()*np.sqrt(3*365),4), np.round(df_2022['funding_rate'].std()*np.sqrt(3*365),4)]},\n",
    "                  index = ['2019', '2020', '2021', '2022'])\n",
    "results['sharpe ratio'] = [np.round(results['mean return'].iloc[0]/results['standard deviation'].iloc[0],2), np.round(results['mean return'].iloc[1]/results['standard deviation'].iloc[1],2), np.round(results['mean return'].iloc[2]/results['standard deviation'].iloc[2],2), np.round(results['mean return'].iloc[3]/results['standard deviation'].iloc[3],2)]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabe4572",
   "metadata": {},
   "source": [
    "\n",
    "We want to test different hypotheses about the relationship of the funding rate with other market parameters.\n",
    "- H1: The funding rate is impacted by the returns of the underlying. The funding rate is high during bull markets.\n",
    "- H2: The funding rate is impacted by volatility in the market. The spread between perpetual and index widens.\n",
    "- H3: The funding rate is impacted by volume in the market. High volumes decreased the spread between perpetual and index.\n",
    "- H_future: The funding rate is impacted by retail involvement. -> How to test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d02b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula as smf\n",
    "import statsmodels.api\n",
    "import statsmodels.stats as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17086292",
   "metadata": {},
   "outputs": [],
   "source": [
    "funding_rate = pd.read_csv('rate_eth_usdt.csv', parse_dates=['timestamp'])\n",
    "perp = pd.read_csv('perp_eth_usdt_1h.csv', parse_dates=['timestamp'])\n",
    "spot = pd.read_csv('spot_eth_usdt_1h.csv', parse_dates=['timestamp'])\n",
    "\n",
    "#rate_sample = rate[(rate['timestamp'] >= '2021-03-01') & (rate['timestamp'] <= '2022-03-01')].reset_index(drop=True)\n",
    "#perp_sample = perp[(perp['timestamp'] >= '2021-03-01') & (perp['timestamp'] <= '2022-03-01')].reset_index(drop=True)\n",
    "#spot_sample = spot[(spot['timestamp'] >= '2021-03-01') & (spot['timestamp'] <= '2022-03-01')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5d06ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We prepare a simpel panel for the regression. Note: The funding rate is measured every 8h. We gather the prices of perpetual swaps and and spot every hour.\n",
    "#Thus we map all the data on equal timestamps, resulting in 8h intervals over 2.5 years.\n",
    "\n",
    "panel = funding_rate[['epoch', 'timestamp', 'rate']]\n",
    "panel = panel.rename(columns={'rate': 'funding_rate'})\n",
    "\n",
    "panel = pd.merge(panel,\n",
    "                 perp[['epoch', 'open', 'volume']],\n",
    "                 on='epoch', \n",
    "                 how='left')\n",
    "panel = panel.rename(columns={'open': 'perp', 'volume': 'vol_perp'})\n",
    "\n",
    "panel = pd.merge(panel,\n",
    "                 spot[['epoch', 'open', 'volume']],\n",
    "                 on='epoch', \n",
    "                 how='left')\n",
    "panel = panel.rename(columns={'open': 'spot', 'volume': 'vol_spot'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c05f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel['vol_spot_perp'] = panel['vol_spot']/panel['vol_perp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3539d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate funding_rate t-1\n",
    "panel['previous_funding_rate'] = panel['funding_rate'].shift(1)\n",
    "#calculate spot return\n",
    "panel['return_t'] = (panel['spot'] - panel['spot'].shift(1))/panel['spot'].shift(1)\n",
    "#7days standard deviation\n",
    "panel['std_7d'] = panel['spot'].rolling(3*7).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20536478",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel = panel.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20861490",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = smf.api.ols('funding_rate ~ return_t + previous_funding_rate + std_7d + vol_perp + vol_spot + vol_spot_perp', data = panel).fit()\n",
    "results.summary2()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bd436c",
   "metadata": {},
   "source": [
    "The returns on the spot market, the previous funding rate $fr_{t-1}$ as well as the trading volume on the perpetual market are statistically significant. \n",
    "Suprisingly the volatiliy does not have and impact.\n",
    "Overall the variables explain 57.6% ($R^2$) of the overall variance.\n",
    "\n",
    "- H1: The funding rate is impacted by the returns of the underlying. The funding rate is high during bull markets. -> not rejected\n",
    "- H2: The funding rate is impacted by volatility in the market. The spread between perpetual and index widens. -> rejected\n",
    "- H3: The funding rate is impacted by volume in the market. High volumes decreased the spread between perpetual and index. -> not rejected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2e51a3",
   "metadata": {},
   "source": [
    "### 3) CIP arbitrage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211ab3bd",
   "metadata": {},
   "source": [
    "Lastly we study deviations from the covered interest parity. The CIP dictates the relation between spot, futures and interest rate differentials.\n",
    "Whereas the CIP devation is violated if $(i_{t}^{CRYPTO}-i_{t}^{USD})*(T-t)+f_{t}^{T}-s_t$ is larger or below zero.\n",
    "- For example if the basis ($f_{t}^{T}-s_t$) is higher than the interest rate differential ($i_{t}^{CRYPTO}-i_{t}^{USD}$), an arbitrageur could sell the future, buy the spot financed with a USD loan, and invest the proceeds at the $i_{t}^{CRYPTO}$ interest rate.\n",
    "- We scale the daily interest rate differential to match the maturity of the futures by multiplying with the time to maturity ($T-t$, i.e. 8/24*365)\n",
    "- We calculate the gross return (before substracting fees and transactions costs) and imply a trade size of \\$1mn to account for slipage.\n",
    "- We calculate the profitability for different thresholds $A$, for a strategy when the CIP violation is larger than $A=$\\{0.1, 0.01, 0.001}\n",
    "\n",
    "- As interest rate we take the compound.finance rates, it is as \"close as big banks can borrow\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00546f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spot = pd.read_csv('spot_eth_usdt_1h.csv', parse_dates=['timestamp'])\n",
    "perp = pd.read_csv('perp_eth_usdt_1h.csv', parse_dates=['timestamp'])\n",
    "i_crypto = pd.read_csv('interest_eth.csv')\n",
    "i_usdt = pd.read_csv('interest_usdt.csv')\n",
    "i_crypto['timestamp'] = pd.to_datetime(i_crypto['timestamp'], format='%d/%m/%Y %H.%M')\n",
    "i_usdt['timestamp'] = pd.to_datetime(i_usdt['timestamp'], format='%d/%m/%Y %H.%M')\n",
    "i_crypto = i_crypto.drop(columns=[i_crypto.columns[4]])\n",
    "i_usdt = i_usdt.drop(columns=[i_usdt.columns[4]])\n",
    "funding_rate_crypto = pd.read_csv('rate_eth_usdt.csv', parse_dates=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedb4235",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_crypto['day'] = i_crypto['timestamp'].dt.round('D')\n",
    "i_usdt['day'] = i_usdt['timestamp'].dt.round('D')\n",
    "funding_rate_crypto['day'] = funding_rate_crypto['timestamp'].dt.round('D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218b28ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel = funding_rate_crypto[['epoch', 'timestamp', 'day', 'rate']]\n",
    "panel = panel.rename(columns={'close': 'funding_rate'})\n",
    "\n",
    "panel = pd.merge(panel,\n",
    "                 spot[['epoch', 'close']],\n",
    "                 on='epoch', \n",
    "                 how='left')\n",
    "panel = panel.rename(columns={'close': 'spot'})\n",
    "\n",
    "\n",
    "panel = pd.merge(panel,\n",
    "                 perp[['epoch', 'close']],\n",
    "                 on='epoch', \n",
    "                 how='left')\n",
    "panel = panel.rename(columns={'close': 'perp'})\n",
    "\n",
    "panel = pd.merge(panel,\n",
    "                 i_crypto[['day', 'apy']],\n",
    "                 on='day', \n",
    "                 how='right')\n",
    "panel = panel.rename(columns={'apy': 'icrypto'})\n",
    "\n",
    "panel = pd.merge(panel,\n",
    "                 i_usdt[['day', 'apy']],\n",
    "                 on='day', \n",
    "                 how='right')\n",
    "panel = panel.rename(columns={'apy': 'iusdt'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdc8b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel['cip'] = (np.log(panel['perp']) - np.log(panel['spot'])) - panel['icrypto']/(365*3) + panel['iusdt']/(365*3)\n",
    "#taking the absolute mean\n",
    "mean = np.round(abs(panel['cip']).mean(),6)\n",
    "print(f'The mean deviation from the covered interest rate parity is {mean*100}%. Sampled over 500 days from 10/2020 till 03/2022.')\n",
    "print(f'Capturing the deviation each 8h would result in a yield of {mean*100*3*365}%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c80ee67",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'panel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8aa23597eceb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# We calculate the profitability for different thresholds  ùê¥, for a strategy when the CIP violation is larger than  ùê¥={0.1, 0.01, 0.001}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpanel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'abs_cip'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpanel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'panel' is not defined"
     ]
    }
   ],
   "source": [
    "# We calculate the profitability for different thresholds  ùê¥, for a strategy when the CIP violation is larger than  ùê¥={0.1, 0.01, 0.001}\n",
    "panel['abs_cip'] = abs(panel['cip'])\n",
    "\n",
    "A = [0.1, 0.01, 0.001]\n",
    "\n",
    "strategies = panel[panel['abs_cip'] > A[0]]\n",
    "if len(strategies) == 0:\n",
    "    print(f'No cip devation larger than ùê¥={A[0]}')\n",
    "\n",
    "strategies = panel[panel['abs_cip'] > A[1]]\n",
    "if len(strategies) == 0:\n",
    "    print(f'No cip devation larger than ùê¥={A[1]}')\n",
    "\n",
    "strategies = panel[panel['abs_cip'] > A[2]]\n",
    "strategies = strategies.reset_index(drop=True)\n",
    "strategies['.001'] = 0.0\n",
    "strategies['.001'][0] = 1 * (1+strategies['abs_cip'][0])\n",
    "\n",
    "for i in range(1,len(strategies)):\n",
    "    strategies['.001'][i] = strategies['.001'][i-1]*(1+strategies['abs_cip'][i])\n",
    "    \n",
    "result = np.round(strategies['.001'].iloc[-1]-1,4)\n",
    "\n",
    "print(f'Perfectly exploiting cip devation larger than ùê¥={A[2]}, yields {result*100}% per annum (compounded).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478ef9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "791155a7",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3d4512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tests for regression\n",
    "\n",
    "# Adj R¬≤\n",
    "results.rsquared_adj\n",
    "\n",
    "#scatter residuals\n",
    "results.resid\n",
    "plt.scatter(x=results.resid.index, y=results.resid)\n",
    "\n",
    "# Durbin-Watson\n",
    "dw = ss.stattools.durbin_watson(results.resid) #p-value\n",
    "# JB \n",
    "jb = ss.stattools.jarque_bera(results.resid)\n",
    "jb[1] # p-value\n",
    "# KS\n",
    "ks = ss.diagnostic.kstest_normal(results.resid)[1] #p-value\n",
    "ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938fef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the funding rate based on the data\n",
    "panel = spot[['epoch', 'timestamp', 'close']]\n",
    "panel = panel.rename(columns={'close': 'spot'})\n",
    "\n",
    "panel = pd.merge(panel,\n",
    "                 perp[['epoch', 'close']],\n",
    "                 on='epoch', \n",
    "                 how='left')\n",
    "panel = panel.rename(columns={'close': 'perp'})\n",
    "\n",
    "panel = panel.dropna()\n",
    "#sample\n",
    "panel = panel.iloc[::8, :]\n",
    "\n",
    "panel['premium'] = (panel['perp']-panel['spot'])/panel['spot']\n",
    "\n",
    "interest = 0.0001\n",
    "panel['fr'] = (panel['premium'] + interest)\n",
    "\n",
    "panel['fr'].mean()*3*365"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
